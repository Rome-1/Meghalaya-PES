method: bayes  # Bayesian optimization
early_terminate:
  type: hyperband  # Use Hyperband for early stopping
  max_iter: 40  # formerly 81; Maximum iterations (for example, max number of epochs)
  s: 4  # Hyperband aggressiveness factor (higher value means more aggressive stopping)
metric:
  name: validation_AUC  # Metric to optimize
  goal: minimize  # Minimize the validation loss

parameters:
  region:
    value: "meghalaya_only" 

  modeltype:
    value: "3D"

  kernel_size:
    values:
      - [ [3, 3], [2, 3, 3], [3, 3], [2, 3, 3] ]

  size:
    values: [25, 29, 35, 39, 45, 49, 55, 69]

  dropout:
    distribution: uniform
    min: 0.1
    max: 0.6

  levels:
    values: [[10], [12], [14]]

  batch_size:
    values: [64, 128, 256, 512, 1024, 2048]  # Trying two different batch sizes

  hidden_dim1:
    values: [32, 64, 128, 256]

  hidden_dim2:
    values: [32, 64, 128, 256]

  hidden_dim3:
    values: [16, 32, 64, 128]

  lr:
    distribution: log_uniform_values  # Log uniform distribution for learning rate
    min: 0.000005
    max: 0.01

  weight_decay:
    value: 0

  n_splits:
    value: 5

  AUC:
    value: true

  BCE_Wloss:
    value: false

  FNcond:
    value: false

  n_epochs:
    values: [1] # epochs

  patience:
    value: 1

  training_time:
    values: [21] # hours

  pos_weight:
    values: [2, 5, 10]

  train_times:
    values: [1, 2, 4, 8]

  test_times:
    values: [1, 2, 4, 8]

  w:
    value: 10

  stop_batch:
    value: null

  print_batch:
    value: 10000

  start_year:
    value: 15

  end_year:
    value: 19

  train_years:
    value: 4

  # Data layers drawn from configs.py -> wandb_data_layers
